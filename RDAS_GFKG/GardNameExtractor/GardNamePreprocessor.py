# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N6TG1DlDxPkbv7EJnxZ_cjoHZF1byXt4
"""

import pandas as pd
# Read the CSV file into a Pandas DataFrame
#Gard = pd.read_csv('/content/exporttttt.csv')
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
nltk.download('stopwords')
nltk.download('punkt')
import re
import json
import ast
from itertools import permutations

def extract_words_from_json_string(json_string):
    try:
        word_list = json.loads(json_string)
        words = [word.replace('"', '').strip() for word in word_list ]
        return words
    except (json.JSONDecodeError, TypeError) as e:
        #print(f"Error decoding JSON: {e}")
        return []

def remove_similar_strings(df):
    for i in df.index:
        if i % 2000 ==0 : print(i)
        for j in df.index:
            if i != j:
                string_a = df['GardName'][i]
                list_b = df['Synonyms'][j]
                for item in list_b:  # Using [:] for iterating a copy of the list
                    if item == string_a:
                        list_b.remove(item)
    return df

def extract_words_from_json_string2(input_string):
    try:
        # Use ast.literal_eval to safely convert the string to a list
        result_list = ast.literal_eval(input_string)
        if isinstance(result_list, list):
            return result_list
        else:
            raise ValueError("Input is not a string representation of a list.")
    except (ValueError, SyntaxError) as e:
        print(f"Error converting string to list: {e}")
        return None

def len_chcek(row):
        return [w for w in row if (len(w) >4) or (w == "sars") ]



#Gard = pd.read_csv('/content/Gard_V1.csv')
#######################          BOW       ########################################################################

def generate_term_orders(terms):
    words = terms.split()
    if len(words) ==2:
      all_permutations = list(permutations(words))
      orders = [' '.join(permutation) for permutation in all_permutations]
      return orders
    else: return [terms]

def generate_term_orders_list_of_sords(words):
    X=[]
    for i in words:
      X+=generate_term_orders(i)
    return X

########################      Removing stop words  #########################################################
def process_row(row):
    words = row.split()
    if len(words) > 2 :
        words = [word.lower()  for word in words if word.lower() not in ['syndrome','syndromes', 'disease','diseases']]
    return ' '.join(words)
def process_row_list(row):
      return [process_row(w) for w in row]

def remove_stop_words(text):
    stop_words = set(stopwords.words('english'))
    words = word_tokenize(text)
    filtered_words = [word for word in words if word.lower() not in stop_words]
    return ' '.join(filtered_words)
def process_row_list_2(row):
    return [remove_stop_words(w) if (remove_stop_words(w) != '' and len(w.split()) > 2) else w for w in row]



########################      Text stemming  #########################################################
def stem_text(text):
    # Initialize the Porter Stemmer
    stemmer = PorterStemmer()
    # Remove punctuation
    text_without_punctuation = re.sub(r'[^\w\s]', '', text)
    # Tokenize the text into words
    words = word_tokenize(text_without_punctuation)
    # Perform stemming on each word
    stemmed_words = [stemmer.stem(word) for word in words]
    # Join the stemmed words back into a single string
    stemmed_text = ' '.join(stemmed_words)
    return stemmed_text
def stem_text_list(row):
      return [stem_text(w) for w in row if len(stem_text(w)) >2 ]

def GardNamePreprocessor(Gard):
   Gard['GardName'] = Gard['GardName'].apply(lambda x: str(x).replace('"', '').lower())
   Gard['Synonyms'] = Gard['Synonyms'].apply(lambda x: extract_words_from_json_string(str(x).lower()))
   Gard= remove_similar_strings(Gard)
   Gard['Synonyms'] = Gard['Synonyms'].apply(lambda x: extract_words_from_json_string(x))
   Gard['Synonyms'] =Gard['GardName'].apply(lambda x: [x])+Gard['Synonyms']
   #Gard['Synonyms_bow']=Gard['Synonyms'].apply(lambda x: generate_term_orders_list_of_sords(x) )
   Gard['Synonyms_sw'] = Gard['Synonyms'].apply(lambda x: process_row_list(x))
   Gard['Synonyms_sw_bow']=Gard['Synonyms_sw'].apply(lambda x: generate_term_orders_list_of_sords(x) )
   Gard['Synonyms_sw_bow']=Gard['Synonyms_sw_bow'].apply(lambda x: list(set(len_chcek(x))) )
   #Gard['Synonyms_sw_nltk'] = Gard['Synonyms_sw'].apply(lambda x: process_row_list_2(x))
   #Gard['Synonyms_sw_nltk']=Gard['Synonyms_sw_nltk']+Gard['Synonyms_sw']
   #Gard['Synonyms_sw_nltk'] = Gard['Synonyms_sw_nltk'].apply(lambda x: list(set(x)))
   #Gard['Synonyms_stem'] = Gard['Synonyms'].apply(lambda x: stem_text_list(x))
   #Gard['Synonyms_stem_bow']=Gard['Synonyms_stem'].apply(lambda x: generate_term_orders_list_of_sords(x) )
   Gard['Synonyms_sw_stem'] = Gard['Synonyms_sw'].apply(lambda x: stem_text_list(x))
   Gard['Synonyms_sw_stem_bow']=Gard['Synonyms_sw_stem'].apply(lambda x: generate_term_orders_list_of_sords(x) )
   Gard['Synonyms_sw_stem'] = Gard['Synonyms_sw'].apply(lambda x:list(set(len_chcek(x))) )
   Gard['Synonyms_sw_stem_bow']=Gard['Synonyms_sw_stem_bow'].apply(lambda x: list(set(len_chcek(x))) )
   Gard['Synonyms_sw'] = Gard['Synonyms'].apply(lambda x: list(set(len_chcek(x))) )
   return Gard
